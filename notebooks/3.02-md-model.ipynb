{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ca2ab4-593c-42a0-b30f-8e0d96175fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing scikit-learn modules for machine learning tasks\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b9fb32-23a5-4945-b7a0-9e695bc4fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('../data/processed/data_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15973916-9811-4352-96e5-a96f66a67fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize different classifiers for evaluation\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(C=0.1),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(max_depth=5),\n",
    "    'RandomForestClassifier': RandomForestClassifier(n_estimators=100, max_depth=5),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVC': SVC(C=0.1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffeb6b1-d3e5-4906-a304-f705498cf251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature and target variables\n",
    "X_cat = ['formation']\n",
    "X_num = data.drop(labels=['date',\n",
    "                          'round',\n",
    "                          'result',\n",
    "                          'gf',\n",
    "                          'ga',\n",
    "                          'opponent',\n",
    "                          'formation',\n",
    "                          'season',\n",
    "                          'team',\n",
    "                          'gdiff',\n",
    "                          'xgdiff',\n",
    "                          'points',\n",
    "                          'exppoints'],\n",
    "                          axis=1\n",
    "                 ).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9becb221-b53d-4da9-937a-1e8f856d687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function which fits all the models from the dictionary above\n",
    "def model_function(data, target, X_cat, X_num, models, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Trains and evaluates multiple models with preprocessing pipelines for both categorical \n",
    "    and numerical features, returning model performance including accuracy, confusion matrices, \n",
    "    and classification reports.\n",
    "\n",
    "    :param data: the input data containing features and target column\n",
    "    :param target: the name of the target column to be predicted\n",
    "    :param X_cat: list of categorical feature column names\n",
    "    :param X_num: list of numerical feature column names\n",
    "    :param models: a dictionary of model names and their corresponding sklearn classifiers\n",
    "    :param test_size: the proportion of the data to be used as test set\n",
    "    :param random_state: random seed for reproducibility\n",
    "    :return: DataFrame comparing accuracy scores of the models, \n",
    "             a dictionary of DataFrames for confusion matrices,\n",
    "             and a dictionary of DataFrames for classification reports\n",
    "    \"\"\"\n",
    "\n",
    "    # Define preprocessing pipelines\n",
    "    cat_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    num_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', cat_pipeline, X_cat),\n",
    "            ('num', num_pipeline, X_num)\n",
    "        ])\n",
    "\n",
    "    # Split the data into features (X) and target (y)\n",
    "    X = data.drop(columns=[target])\n",
    "    y = data[target]\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Encode target variable\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "\n",
    "    # Initialize DataFrame for model comparison\n",
    "    models_comparison = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
    "\n",
    "    # Initialize dictionaries for confusion matrices and classification reports\n",
    "    confusion_matrices = {}\n",
    "    classification_reports = {}\n",
    "\n",
    "    # Iterate through different classifiers provided in the dictionary\n",
    "    for name, model in models.items():\n",
    "\n",
    "        # Create a pipeline for each model\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        # Fit the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test data\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Compute accuracy\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Compute classification report\n",
    "        class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        # Append results to the accuracy comparison DataFrame\n",
    "        models_comparison = pd.concat([models_comparison, pd.DataFrame({'Model': [name], 'Accuracy': [acc]})])\n",
    "\n",
    "        # Store the confusion matrix as a DataFrame\n",
    "        confusion_matrices[name] = pd.DataFrame(conf_matrix, \n",
    "                                                 index=[f'True {i}' for i in range(conf_matrix.shape[0])],\n",
    "                                                 columns=[f'Pred {i}' for i in range(conf_matrix.shape[1])])\n",
    "\n",
    "        # Store the classification report as a DataFrame\n",
    "        classification_reports[name] = pd.DataFrame(class_report).transpose()\n",
    "\n",
    "    # Sort by accuracy\n",
    "    models_comparison = models_comparison.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return models_comparison, confusion_matrices, classification_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14301df0-c4ee-4057-a8e3-b299a633ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matid\\AppData\\Local\\Temp\\ipykernel_2716\\1503174640.py:81: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  models_comparison = pd.concat([models_comparison, pd.DataFrame({'Model': [name], 'Accuracy': [acc]})])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                    Model  Accuracy\n",
       " 0  RandomForestClassifier  0.719737\n",
       " 1      LogisticRegression  0.713158\n",
       " 2                     SVC  0.713158\n",
       " 3  DecisionTreeClassifier  0.682895\n",
       " 4    KNeighborsClassifier  0.677632,\n",
       " {'LogisticRegression':         Pred 0  Pred 1  Pred 2\n",
       "  True 0      39      72      67\n",
       "  True 1      25     243      19\n",
       "  True 2      20      15     260,\n",
       "  'DecisionTreeClassifier':         Pred 0  Pred 1  Pred 2\n",
       "  True 0      26      66      86\n",
       "  True 1      29     226      32\n",
       "  True 2       9      19     267,\n",
       "  'RandomForestClassifier':         Pred 0  Pred 1  Pred 2\n",
       "  True 0       5      89      84\n",
       "  True 1       1     255      31\n",
       "  True 2       0       8     287,\n",
       "  'KNeighborsClassifier':         Pred 0  Pred 1  Pred 2\n",
       "  True 0      57      67      54\n",
       "  True 1      45     218      24\n",
       "  True 2      41      14     240,\n",
       "  'SVC':         Pred 0  Pred 1  Pred 2\n",
       "  True 0      19      89      70\n",
       "  True 1      12     253      22\n",
       "  True 2       7      18     270},\n",
       " {'LogisticRegression':               precision    recall  f1-score     support\n",
       "  0              0.464286  0.219101  0.297710  178.000000\n",
       "  1              0.736364  0.846690  0.787682  287.000000\n",
       "  2              0.751445  0.881356  0.811232  295.000000\n",
       "  accuracy       0.713158  0.713158  0.713158    0.713158\n",
       "  macro avg      0.650698  0.649049  0.632208  760.000000\n",
       "  weighted avg   0.678494  0.713158  0.682067  760.000000,\n",
       "  'DecisionTreeClassifier':               precision    recall  f1-score     support\n",
       "  0              0.406250  0.146067  0.214876  178.000000\n",
       "  1              0.726688  0.787456  0.755853  287.000000\n",
       "  2              0.693506  0.905085  0.785294  295.000000\n",
       "  accuracy       0.682895  0.682895  0.682895    0.682895\n",
       "  macro avg      0.608815  0.612870  0.585341  760.000000\n",
       "  weighted avg   0.638758  0.682895  0.640578  760.000000,\n",
       "  'RandomForestClassifier':               precision    recall  f1-score     support\n",
       "  0              0.833333  0.028090  0.054348  178.000000\n",
       "  1              0.724432  0.888502  0.798122  287.000000\n",
       "  2              0.713930  0.972881  0.823529  295.000000\n",
       "  accuracy       0.719737  0.719737  0.719737    0.719737\n",
       "  macro avg      0.757232  0.629824  0.558666  760.000000\n",
       "  weighted avg   0.745861  0.719737  0.633784  760.000000,\n",
       "  'KNeighborsClassifier':               precision    recall  f1-score     support\n",
       "  0              0.398601  0.320225  0.355140  178.000000\n",
       "  1              0.729097  0.759582  0.744027  287.000000\n",
       "  2              0.754717  0.813559  0.783034  295.000000\n",
       "  accuracy       0.677632  0.677632  0.677632    0.677632\n",
       "  macro avg      0.627472  0.631122  0.627401  760.000000\n",
       "  weighted avg   0.661636  0.677632  0.668087  760.000000,\n",
       "  'SVC':               precision    recall  f1-score     support\n",
       "  0              0.500000  0.106742  0.175926  178.000000\n",
       "  1              0.702778  0.881533  0.782071  287.000000\n",
       "  2              0.745856  0.915254  0.821918  295.000000\n",
       "  accuracy       0.713158  0.713158  0.713158    0.713158\n",
       "  macro avg      0.649545  0.634510  0.593305  760.000000\n",
       "  weighted avg   0.672006  0.713158  0.655572  760.000000})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the results\n",
    "model_function(data, 'result', X_cat, X_num, models, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81f3ac-e15c-4c55-baaa-5edc6543b14d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
